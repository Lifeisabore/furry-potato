# 爬取小猪短租网信息   结果不太理想 有些被限制了 好像是因为超过了设置的最大重定向次数 明天要再练一次
import requests
from bs4 import BeautifulSoup
import time

headers = {
'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'
}

#判断用户的性别 
def judgment_sex(class_name):                      #定义一个性别函数
    if class_name == ['member_ico']:              #右击inspect，发现男性头像为‘member_ico',女性头像为‘member_ico1'，可得此判断句。
        return '男'
    else:
        return '女'

#定义获取详情页面的URL
def get_links(url):                               #定义一个获得链接函数
    wb_data = requests.get(url,headers=headers)           #运用request库

    soup = BeautifulSoup(wb_data.text,'html.parser')       #给soup赋值，运用BeautifulSoup库，使用'html.parser'，速度慢，但好在不用下载c语言课
    links = soup.select('#page_list > ul > li > a')        #给links赋值，并运用select方法，给soup的数据从大到小排列
    for link in links:                                     #这个循环语句不清楚，应该再找资料看一看，这里往后几句代码就不明白
        href = link.get('href')                            #这个href是怎么找到的我是真的找不到
       # print(href) 
        get_info(href)                                     
        time.sleep(3)

#定义获取页面详细信息
def get_info(url):                               #定义一个获得信息函数
    wd_data = requests.get(url,headers=headers)               #运用request库，给wd_data赋值
    soup = BeautifulSoup(wd_data.text,'html.parser')          #给soup赋值，运用BeautifulSoup库
    titles = soup.select('div.pho_info > h4')                 #给titles赋值，运用select方法，copy selector
    addresses = soup.select('div.pho_info > p > span.pr5')
    prices = soup.select('#pricePart > div.day_l > span')
    imgs = soup.select('#floatRightBox > div.js_box.clearfix > div.member_pic > a > img')
    names = soup.select('div.con_l > div.pho_info > h4 > em')
    sexs = soup.select('#floatRightBox > div.js_box.clearfix > div.member_pic > div')

    for title,address,price,img,name,sex in zip(titles,addresses,prices,imgs,names,sexs):
        data = {
            'title' : title.get_text().strip(),
            'address' : address.get_text().strip(),
            'price' : price.get_text().strip(),
            'img' : img.get('src')img.get('src'),
            'name' : name.get_text().strip(),
            'sex': judgment_sex(sex.get('class'))
        }
        print(data)

if __name__ == '__main__':    #为程序主入口，利用列表的推导式列出13个url，并依次调用get_links函数
    urls = ['http://bj.xiaozhu.com/search-duanzufang-p{}-0/'.format(number) for number in range(1,14)]
    for single_url in urls:
        get_links(single_url)
        time.sleep(6)
