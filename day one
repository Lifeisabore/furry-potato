read me

#1.4 python数据结构

#1.4.1 列表

#第一个代码，用到了字符串的切片
list=['peter','lilei','wangwu','xiaoming']
print(list[0])
print([0:])             这里0:后面不加便取了后面所有值
#result
peter
['wangwu','xiaoming']     

#第二个代码，用到了循环语句for
names=['xiaoming','wangwu','peter']
ages=[23,15,58]                   #这里我尝试了一下，用字符串输出的值跟整型一样
for name, age in zip (names, ages):              #这里我尝试把name，age换成a，b，结果输出一致，原因不明。另外我还尝试了把name，age换成names，ages，结果输出一致，在网上查找资料后感觉应该换成names，ages才更准确，也能明白是什么意思。
    print(name,age)                              #还有这里的zip是一个函数，用来把两组或多组不同的对象中的元素打包成一组。
#result
xiaoming 23
wangwu 15
peter 58

#第三个代码，用于存储有一定规律的网页
urls=['http://bj.xiaozhu.com/search-duanzufang-p{}-0/'.format(number)  #这里我试了在代码最后加]并将下行代码的]去掉，但结果错误，原因不明。我试着将下一行代码直接添加到这一行，成功运行。
for number in range (1,14)]
for url in urls:                 #同样是这个代码，如果把url换成包括urls本身在内的其他字母，也可以运行
    print(url)
 #result
http://bj.xiaozhu.com/search-duanzufang-p1-0/
http://bj.xiaozhu.com/search-duanzufang-p2-0/
http://bj.xiaozhu.com/search-duanzufang-p3-0/
http://bj.xiaozhu.com/search-duanzufang-p4-0/
http://bj.xiaozhu.com/search-duanzufang-p5-0/
http://bj.xiaozhu.com/search-duanzufang-p6-0/
http://bj.xiaozhu.com/search-duanzufang-p7-0/
http://bj.xiaozhu.com/search-duanzufang-p8-0/
http://bj.xiaozhu.com/search-duanzufang-p9-0/
http://bj.xiaozhu.com/search-duanzufang-p10-0/
http://bj.xiaozhu.com/search-duanzufang-p11-0/
http://bj.xiaozhu.com/search-duanzufang-p12-0/
http://bj.xiaozhu.com/search-duanzufang-p13-0/

#1.4.2 字典

#书上说字典的操作以后再说，这里仅有一个格式

user_info {
   'name':'xiaoming',
   'age':'23'
   'sex':'man'
}

#1.4.3 元组和集合

#在爬虫里，元组和集合很少用到。元组只能查看不能修改。格式如下：

tuple=(1,2,3)  #这里的tuple即是元组的意思

#集合就像是数学里的集合。每个集合的元素是无序的，不可以有重复的对象，因此通过集合可以把重复的数据去除。

list=['xiaoming','zhangyun','xiaoming']
set=set(list)               #这里的set就是集合的意思
print(set)
#result ('zhangyun','xiaoming')  #我尝试了print(set(list))就可以出来结果，更简单。


#1.5 python面对对象暂时不太清楚，先放一放。

# 2.0 爬虫

#2.1 使用爬虫数据库需要先现在pip，可在命令行还有pycharm中下载。具体步骤网上皆有

#2.2 爬虫三大库

#2.2.1 Requests库

#第一类，没有反爬虫限制，直接输入网站就能得到

import requests
res=requests.get('http://bj.xiaozhu.com/')    #网站是小猪短租网的
print(res)                                    #如果请求网站成功，则显示<Response [200]>, 失败则为404，400样式
print(res.text)                               #打印文本部分太长，这里不表示出来。打印出来的为网站的源代码


#第二类，有反爬虫限制，需要用个假开头

import requests
headers = {'User-Agent':"Mozilla/5.0 "}                    #这里的headers需要填写网址的User-Agent，但我发现说明号前后随便填什么都行，根本不影响
res = requests.get('https://www.youtube.com/watch?v=rfscVS0vtbw',headers=headers)      #某youtube视频
print(res.text)

#2.2.2 BeautifulSoup库（说是能优化request得到的数据，以标准缩进格式的结构输出，为数据的过滤提取做好准备）

import requests
from bs4 import BeautifulSoup        #只是跟前面比多了这一步而已，
headers={'xxx':'wwww'}
res=requests.get('https://blog.csdn.net/huatian5/article/details/74502687',headers=headers)
print(res.text)

# 三种方法，find（），find_all()和select()

# find()  和 find_all()具体方法不明,格式如下
find_all(tag,attibutes,recursive,text,limit,keywords)
find(tag,attibutes,recursive,text,keywords)   #说是两个方法用法差不多，并且常用的是前两个参数

# select()
soup.select(div.item > a > h1) #括号内的内容通过chrome复制得到。类似于 中国>湖南>长沙,从大到小，提取需要的信息。

#范例用法一

import requests                        #这一个跟下一个就不谈了，都要先输入一下，不然没法用select
from bs4 import BeautifulSoup
headers={'User-Agent':'Mozilla/5.0'}      #这个我发现还是可以随便定，不知道为什么书上说要找user-agent。不过不能忘了加引号，不然出不来结果
res=requests.get('https://bj.xiaozhu.com/%E5%8C%97%E4%BA%AC_1h5gbS-duanzufang-20/?putkey=%E5%8C%97%E4%BA%AC',headers=headers)
soup=BeautifulSoup(res.text,'html.parser')         #这里的‘html.parser‘是一种解析类型，具体用法不明
A=soup.select('#page_list > ul > li:nth-child(1) > div.result_btm_con.lodgeunitname > div:nth-child(1) > span > i')     #这串代码输出的是价格，所以我们鼠标至价格那一栏右击选择copy selector，把那一串编码复制过来。此外书上说要用li:nth-child(1)转为li:nth-oftype(1),但我没转也没事
print(A)                                #我试了携程和airbnb，但只有小猪网能出来结果，不知道为什么。难道是因为反爬虫限制么？
#result
[<i>368</i>]

#范例用法二
#这里跟上个例子的不同在于多了最后一行代码，即将网页的所以价格打印出来，而不是像上个例子一样只打印一个
import requests  
from bs4 import BeautifulSoup
headers={'User-Agent':'Mozilla/5.0'}
res=requests.get('https://bj.xiaozhu.com/',headers=headers)
soup=BeautifulSoup(res.text,'html.parser')
A=soup.select('#page_list > ul > li > div.result_btm_con.lodgeunitname > div:nth-child(1) > span > i')   #这里的li：nth要换成li
for price in A:
    print(price)           #结果为一列字符串数字。

#范例用法三
#这里跟用法三相比也是只多加了一部分get_text(),即只打印出数字
import requests
from bs4 import BeautifulSoup
headers={'User-Agent':'Mozilla/5.0'}
res=requests.get('https://bj.xiaozhu.com/',headers=headers)
soup=BeautifulSoup(res.text,'html.parser')
A=soup.select('#page_list > ul > li > div.result_btm_con.lodgeunitname > div:nth-child(1) > span > i')
for price in A:
    print(price.get_text())    #结果只有一列数字
