read me

#1.4 python数据结构

#1.4.1 列表

#第一个代码，用到了字符串的切片
list=['peter','lilei','wangwu','xiaoming']
print(list[0])
print([0:])             这里0:后面不加便取了后面所有值
#result
peter
['wangwu','xiaoming']     

#第二个代码，用到了循环语句for
names=['xiaoming','wangwu','peter']
ages=[23,15,58]                   #这里我尝试了一下，用字符串输出的值跟整型一样
for name, age in zip (names, ages):              #这里我尝试把name，age换成a，b，结果输出一致，原因不明。另外我还尝试了把name，age换成names，ages，结果输出一致，在网上查找资料后感觉应该换成names，ages才更准确，也能明白是什么意思。
    print(name,age)                              #还有这里的zip是一个函数，用来把两组或多组不同的对象中的元素打包成一组。
#result
xiaoming 23
wangwu 15
peter 58

#第三个代码，用于存储有一定规律的网页
urls=['http://bj.xiaozhu.com/search-duanzufang-p{}-0/'.format(number)  #这里我试了在代码最后加]并将下行代码的]去掉，但结果错误，原因不明。我试着将下一行代码直接添加到这一行，成功运行。
for number in range (1,14)]
for url in urls:                 #同样是这个代码，如果把url换成包括urls本身在内的其他字母，也可以运行
    print(url)
 #result
http://bj.xiaozhu.com/search-duanzufang-p1-0/
http://bj.xiaozhu.com/search-duanzufang-p2-0/
http://bj.xiaozhu.com/search-duanzufang-p3-0/
http://bj.xiaozhu.com/search-duanzufang-p4-0/
http://bj.xiaozhu.com/search-duanzufang-p5-0/
http://bj.xiaozhu.com/search-duanzufang-p6-0/
http://bj.xiaozhu.com/search-duanzufang-p7-0/
http://bj.xiaozhu.com/search-duanzufang-p8-0/
http://bj.xiaozhu.com/search-duanzufang-p9-0/
http://bj.xiaozhu.com/search-duanzufang-p10-0/
http://bj.xiaozhu.com/search-duanzufang-p11-0/
http://bj.xiaozhu.com/search-duanzufang-p12-0/
http://bj.xiaozhu.com/search-duanzufang-p13-0/

#1.4.2 字典

#书上说字典的操作以后再说，这里仅有一个格式

user_info {
   'name':'xiaoming',
   'age':'23'
   'sex':'man'
}

#1.4.3 元组和集合

#在爬虫里，元组和集合很少用到。元组只能查看不能修改。格式如下：

tuple=(1,2,3)  #这里的tuple即是元组的意思

#集合就像是数学里的集合。每个集合的元素是无序的，不可以有重复的对象，因此通过集合可以把重复的数据去除。

list=['xiaoming','zhangyun','xiaoming']
set=set(list)               #这里的set就是集合的意思
print(set)
#result ('zhangyun','xiaoming')  #我尝试了print(set(list))就可以出来结果，更简单。


#1.5 python面对对象暂时不太清楚，先放一放。

# 2.0 爬虫

#2.1 使用爬虫数据库需要先现在pip，可在命令行还有pycharm中下载。具体步骤网上皆有

#2.2 爬虫三大库

#2.2.1 Requests库

#第一类，没有反爬虫限制，直接输入网站就能得到

import requests
res=requests.get('http://bj.xiaozhu.com/')    #网站是小猪短租网的
print(res)                                    #如果请求网站成功，则显示<Response [200]>, 失败则为404，400样式
print(res.text)                               #打印文本部分太长，这里不表示出来。打印出来的为网站的源代码


#第二类，有反爬虫限制，需要用个假开头

import requests
headers = {'User-Agent':"Mozilla/5.0 "}                    #这里的headers需要填写网址的User-Agent，但我发现说明号前后随便填什么都行，根本不影响
res = requests.get('https://www.youtube.com/watch?v=rfscVS0vtbw',headers=headers)      #某youtube视频
print(res.text)


